{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9615d8",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46e7a4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "924a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497c14e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(\"dataset/cleaned/teams.csv\")\n",
    "df_teams_post = pd.read_csv(\"dataset/cleaned/teams_post.csv\")\n",
    "df_series_post = pd.read_csv(\"dataset/cleaned/series_post.csv\")\n",
    "df_players = pd.read_csv(\"dataset/cleaned/players.csv\")\n",
    "df_players_teams = pd.read_csv(\"dataset/cleaned/players_teams.csv\")\n",
    "df_coaches = pd.read_csv(\"dataset/cleaned/coaches.csv\")\n",
    "df_awards_players = pd.read_csv(\"dataset/cleaned/awards_players.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eef85",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ba417ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (base rf model): 0.0207938461538461 \n",
      "Mean absolute error (best rf model): 0.024819156095444182 \n",
      "[0.52386 0.46817 0.44569 0.54054 0.6207  0.54486 0.46278 0.3813  0.67131\n",
      " 0.32875 0.50217 0.57383 0.49858]\n",
      "[0.53280512 0.44933468 0.43779009 0.53872279 0.6230763  0.54002277\n",
      " 0.45700784 0.38485574 0.65783291 0.31465525 0.50693841 0.57040202\n",
      " 0.50238762]\n",
      "Team: ATL\tPredicted winPercentage: 0.532805122022857\tActual winPercentage: 0.529\n",
      "Team: CHI\tPredicted winPercentage: 0.4493346846116841\tActual winPercentage: 0.471\n",
      "Team: CON\tPredicted winPercentage: 0.43779008826168375\tActual winPercentage: 0.471\n",
      "Team: DET\tPredicted winPercentage: 0.5387227940315404\tActual winPercentage: 0.529\n",
      "Team: IND\tPredicted winPercentage: 0.6230763022070528\tActual winPercentage: 0.647\n",
      "Team: LAS\tPredicted winPercentage: 0.5400227656672025\tActual winPercentage: 0.529\n",
      "Team: MIN\tPredicted winPercentage: 0.4570078385805371\tActual winPercentage: 0.412\n",
      "Team: NYL\tPredicted winPercentage: 0.38485574102980363\tActual winPercentage: 0.382\n",
      "Team: PHO\tPredicted winPercentage: 0.6578329113247867\tActual winPercentage: 0.676\n",
      "Team: SAC\tPredicted winPercentage: 0.3146552516228326\tActual winPercentage: 0.353\n",
      "Team: SAS\tPredicted winPercentage: 0.5069384076186614\tActual winPercentage: 0.441\n",
      "Team: SEA\tPredicted winPercentage: 0.5704020172790171\tActual winPercentage: 0.588\n",
      "Team: WAS\tPredicted winPercentage: 0.5023876155972293\tActual winPercentage: 0.471\n"
     ]
    }
   ],
   "source": [
    "# ### dps vemos estaticas de rebounds, steals, blocks, turnovers, etc para prever as estatisticas da equipa no ano seguinte\n",
    "\n",
    "# save year 2010\n",
    "df_teams_2010 = df_teams[df_teams.year == 10]\n",
    "# \n",
    "# \n",
    "# Vai depender muito do que eles nos dão para testarmos.... provavelmente só nos vão dar a composição das equipas e não estatisiticas de jogos\n",
    "# \n",
    "# \n",
    "\n",
    "#drop where year equals 2010\n",
    "df_teams = df_teams[df_teams.year != 10]\n",
    "tmids = df_teams_2010['tmID']\n",
    "confIds = df_teams_2010['confID']\n",
    "df_teams = df_teams.drop(columns=['tmID', 'year', 'confID'], axis=1)\n",
    "df_teams_2010 = df_teams_2010.drop(columns=['tmID', 'year', 'confID'], axis=1)\n",
    "# remove year and tmID\n",
    "\n",
    "X, Y = df_teams.drop(columns=['winPercentage'], axis=1), df_teams['winPercentage']\n",
    "\n",
    "best_rf = RandomForestRegressor(n_estimators = 600,min_samples_split = 2,min_samples_leaf = 4,max_features = 'auto',max_depth = 40,bootstrap = True)\n",
    "base_rf = RandomForestRegressor()\n",
    "best_model = best_rf.fit(X, Y)\n",
    "base_model = base_rf.fit(X, Y)\n",
    "\n",
    "\n",
    "X_TEST = df_teams_2010.drop(columns=['winPercentage'], axis=1)\n",
    "Y_TEST = df_teams_2010['winPercentage']\n",
    "\n",
    "\n",
    "def mae(test,pred): # Mean absolute error \n",
    "    err = np.mean(abs(test-pred))\n",
    "    return err\n",
    "y_pred_base = base_model.predict(X_TEST)\n",
    "y_pred_best = best_model.predict(X_TEST)\n",
    "print('Mean absolute error (base rf model): {} '.format(mae(Y_TEST,y_pred_base)))\n",
    "print('Mean absolute error (best rf model): {} '.format(mae(Y_TEST,y_pred_best)))\n",
    "print(y_pred_base)\n",
    "print(y_pred_best)\n",
    "\n",
    "#add tmid again to df_teams_2010\n",
    "df_teams_2010['tmID'] = tmids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for every objet show the predicted winPercentage and the actual winPercentage\n",
    "i=0\n",
    "for index, row in df_teams_2010.iterrows():\n",
    "    print(f\"Team: {row['tmID']}\\tPredicted winPercentage: {y_pred_best[i]}\\tActual winPercentage: {row['winPercentage']}\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b04a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eastern Conference\n",
      "IND with probality of 0.6230763022070528\n",
      "DET with probality of 0.5387227940315404\n",
      "ATL with probality of 0.532805122022857\n",
      "WAS with probality of 0.5023876155972293\n",
      "Western Conference\n",
      "PHO with probality of 0.6578329113247867\n",
      "SEA with probality of 0.5704020172790171\n",
      "LAS with probality of 0.5400227656672025\n",
      "SAS with probality of 0.5069384076186614\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# NOTE: This is tested against year 2009. It is able to predict the exact teams that made it to the playoffs because the dataset contains the playoff statistics features for that year.\n",
    "#      However, the teacher won't probably give us the playoff statistics for the year 2010, so we will have to predict the teams that will make it to the playoffs based on other features.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Make a prediction for the 2010 season\n",
    "# say which teams will make it to the playoffs ... only four teams from each conference make it to the playoffs\n",
    "\n",
    "df_teams_2010['confID'] = confIds\n",
    "\n",
    "# add predWinPercentage to df_teams_2010\n",
    "df_teams_2010['predWinPercentage'] = y_pred_best\n",
    "\n",
    "ea_conf = df_teams_2010[df_teams_2010.confID == 'EA']\n",
    "we_conf = df_teams_2010[df_teams_2010.confID == 'WE']\n",
    "\n",
    "\n",
    "# get the top 4 teams from each conference\n",
    "ea_conf = ea_conf.sort_values(by=['predWinPercentage'], ascending=False)\n",
    "we_conf = we_conf.sort_values(by=['predWinPercentage'], ascending=False)\n",
    "\n",
    "\n",
    "# print the teams that will make it to the playoffs\n",
    "\n",
    "print(\"Eastern Conference\")\n",
    "for index, row in ea_conf.head(4).iterrows():\n",
    "    print(f\"{row['tmID']} with probality of {row['predWinPercentage']}\")\n",
    "print(\"Western Conference\")\n",
    "for index, row in we_conf.head(4).iterrows():\n",
    "    print(f\"{row['tmID']} with probality of {row['predWinPercentage']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6433bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def expanding_window_cross_validation(data, model_func, features, num_years):\n",
    "    accuracy_results = []\n",
    "\n",
    "\n",
    "    for i in range(1, num_years):\n",
    "        train_data = data[data['year'].between(1, i)]\n",
    "        test_data = data[data['year'] == (i + 1)]\n",
    "\n",
    "        X_train, X_test = train_data[features], test_data[features]\n",
    "        y_train, y_test = train_data['playoff'], test_data['playoff']\n",
    "\n",
    "        model = model_func()  # Create the model using the provided lambda function\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy_results.append(accuracy)\n",
    "\n",
    "    final_train_data = data[data['year'].between(1, num_years)]\n",
    "    final_test_data = data[data['year'] == (num_years + 1)]\n",
    "\n",
    "    X_final_train, X_final_test = final_train_data[features], final_test_data[features]\n",
    "    y_final_train, y_final_test = final_train_data['playoff'], final_test_data['playoff']\n",
    "\n",
    "    final_model = model_func()\n",
    "    final_model.fit(X_final_train, y_final_train)\n",
    "\n",
    "    final_predictions = final_model.predict(X_final_test)\n",
    "    final_accuracy = accuracy_score(y_final_test, final_predictions)\n",
    "\n",
    "    return accuracy_results, final_accuracy\n",
    "\n",
    "\n",
    "wnba_data = pd.read_csv(\"dataset/cleaned/teams.csv\")\n",
    "num_years = 9 # 9 years of data and 1 year to predict\n",
    "\n",
    "# Selecting the features and target\n",
    "features = ['attend','RoundReached','o_oreb', 'o_dreb', 'o_pf', 'o_stl', 'o_blk', 'o_pts', 'd_oreb', 'd_dreb', 'd_asts', 'd_pf', 'd_to', 'd_blk', 'd_pts', 'min', 'attend', 'RoundReached',\n",
    "            'winPercentage', 'homeWinPercentage', 'awayWinPercentage', 'of_goal', 'of_3pt', 'of_throw', 'of_reb', 'of_assist', 'df_goal', 'df_3pt', 'df_throw', 'df_reb', 'df_steal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6f31ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Define a list of lambda functions for different models with hyperparameters\n",
    "models = [\n",
    "    lambda: RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    #lambda: LogisticRegression(max_iter=1000, random_state=42),\n",
    "    lambda: SVC(C=1.0, kernel='rbf', probability=True),\n",
    "    lambda: GaussianNB(),\n",
    "    lambda: KNeighborsClassifier(n_neighbors=5),\n",
    "    lambda: DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    lambda: MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ecea4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Model name: RandomForestClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Final Accuracy: 1.0\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: SVC\n",
      "Accuracy results for each iteration: [0.56, 0.75, 0.21, 0.69, 0.62, 0.64, 0.69, 0.64]\n",
      "Final Accuracy: 0.69\n",
      "Average accuracy: 0.6\n",
      "=====================================\n",
      "Model name: GaussianNB\n",
      "Accuracy results for each iteration: [0.81, 0.94, 0.43, 0.85, 0.85, 0.71, 0.85, 1.0]\n",
      "Final Accuracy: 0.92\n",
      "Average accuracy: 0.8\n",
      "=====================================\n",
      "Model name: KNeighborsClassifier\n",
      "Accuracy results for each iteration: [0.56, 0.62, 0.5, 0.92, 0.38, 0.43, 0.46, 0.57]\n",
      "Final Accuracy: 0.62\n",
      "Average accuracy: 0.56\n",
      "=====================================\n",
      "Model name: DecisionTreeClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Final Accuracy: 1.0\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: GradientBoostingClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Final Accuracy: 1.0\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: MLPClassifier\n",
      "Accuracy results for each iteration: [0.5, 0.5, 0.57, 0.62, 0.62, 0.57, 0.62, 0.57]\n",
      "Final Accuracy: 0.62\n",
      "Average accuracy: 0.57\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    accuracy_results, final_accuracy = expanding_window_cross_validation(\n",
    "        wnba_data, model, features, num_years)\n",
    "\n",
    "    avg = round(sum(accuracy_results) / len(accuracy_results), 2)\n",
    "\n",
    "    print(f\"=====================================\")\n",
    "    print(\"Model name:\", type(model()).__name__)\n",
    "    print(\"Accuracy results for each iteration:\",\n",
    "          [round(x, 2) for x in accuracy_results])\n",
    "    print(\"Final Accuracy:\", round(final_accuracy, 2))\n",
    "    print(\"Average accuracy:\", avg)\n",
    "\n",
    "print(\"=====================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
