{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9615d8",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46e7a4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "924a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497c14e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(\"dataset/cleaned/teams.csv\")\n",
    "df_teams_post = pd.read_csv(\"dataset/cleaned/teams_post.csv\")\n",
    "df_series_post = pd.read_csv(\"dataset/cleaned/series_post.csv\")\n",
    "df_players = pd.read_csv(\"dataset/cleaned/players.csv\")\n",
    "df_players_teams = pd.read_csv(\"dataset/cleaned/players_teams.csv\")\n",
    "df_coaches = pd.read_csv(\"dataset/cleaned/coaches.csv\")\n",
    "df_awards_players = pd.read_csv(\"dataset/cleaned/awards_players.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eef85",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ba417ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (base rf model): 0.026999999999999913 \n",
      "Mean absolute error (best rf model): 0.02624051181608 \n",
      "[0.52766 0.44758 0.43587 0.54435 0.62006 0.55016 0.45756 0.39749 0.66453\n",
      " 0.31712 0.50495 0.56748 0.50579]\n",
      "[0.53283497 0.44800084 0.43719437 0.53750422 0.62244607 0.54423915\n",
      " 0.46168801 0.39308457 0.65546878 0.32181827 0.50806402 0.56796949\n",
      " 0.50360952]\n",
      "Team: ATL\tPredicted winPercentage: 0.5328349734825353\tActual winPercentage: 0.529\n",
      "Team: CHI\tPredicted winPercentage: 0.448000836029711\tActual winPercentage: 0.471\n",
      "Team: CON\tPredicted winPercentage: 0.4371943733280607\tActual winPercentage: 0.471\n",
      "Team: DET\tPredicted winPercentage: 0.5375042246060031\tActual winPercentage: 0.529\n",
      "Team: IND\tPredicted winPercentage: 0.6224460680592554\tActual winPercentage: 0.647\n",
      "Team: LAS\tPredicted winPercentage: 0.5442391512019968\tActual winPercentage: 0.529\n",
      "Team: MIN\tPredicted winPercentage: 0.4616880104862464\tActual winPercentage: 0.412\n",
      "Team: NYL\tPredicted winPercentage: 0.39308457320022056\tActual winPercentage: 0.382\n",
      "Team: PHO\tPredicted winPercentage: 0.6554687810090237\tActual winPercentage: 0.676\n",
      "Team: SAC\tPredicted winPercentage: 0.3218182706310574\tActual winPercentage: 0.353\n",
      "Team: SAS\tPredicted winPercentage: 0.5080640158984536\tActual winPercentage: 0.441\n",
      "Team: SEA\tPredicted winPercentage: 0.5679694854714996\tActual winPercentage: 0.588\n",
      "Team: WAS\tPredicted winPercentage: 0.5036095192621921\tActual winPercentage: 0.471\n"
     ]
    }
   ],
   "source": [
    "# ### dps vemos estaticas de rebounds, steals, blocks, turnovers, etc para prever as estatisticas da equipa no ano seguinte\n",
    "\n",
    "# save year 2010\n",
    "df_teams_2010 = df_teams[df_teams.year == 10]\n",
    "# \n",
    "# \n",
    "# Vai depender muito do que eles nos dão para testarmos.... provavelmente só nos vão dar a composição das equipas e não estatisiticas de jogos\n",
    "# \n",
    "# \n",
    "\n",
    "#drop where year equals 2010\n",
    "df_teams = df_teams[df_teams.year != 10]\n",
    "tmids = df_teams_2010['tmID']\n",
    "confIds = df_teams_2010['confID']\n",
    "df_teams = df_teams.drop(columns=['tmID', 'year', 'confID'], axis=1)\n",
    "df_teams_2010 = df_teams_2010.drop(columns=['tmID', 'year', 'confID'], axis=1)\n",
    "# remove year and tmID\n",
    "\n",
    "X, Y = df_teams.drop(columns=['winPercentage'], axis=1), df_teams['winPercentage']\n",
    "\n",
    "best_rf = RandomForestRegressor(n_estimators = 600,min_samples_split = 2,min_samples_leaf = 4,max_features = 'auto',max_depth = 40,bootstrap = True)\n",
    "base_rf = RandomForestRegressor()\n",
    "best_model = best_rf.fit(X, Y)\n",
    "base_model = base_rf.fit(X, Y)\n",
    "\n",
    "\n",
    "X_TEST = df_teams_2010.drop(columns=['winPercentage'], axis=1)\n",
    "Y_TEST = df_teams_2010['winPercentage']\n",
    "\n",
    "\n",
    "def mae(test,pred): # Mean absolute error \n",
    "    err = np.mean(abs(test-pred))\n",
    "    return err\n",
    "y_pred_base = base_model.predict(X_TEST)\n",
    "y_pred_best = best_model.predict(X_TEST)\n",
    "print('Mean absolute error (base rf model): {} '.format(mae(Y_TEST,y_pred_base)))\n",
    "print('Mean absolute error (best rf model): {} '.format(mae(Y_TEST,y_pred_best)))\n",
    "print(y_pred_base)\n",
    "print(y_pred_best)\n",
    "\n",
    "#add tmid again to df_teams_2010\n",
    "df_teams_2010['tmID'] = tmids\n",
    "\n",
    "\n",
    "\n",
    "# for every objet show the predicted winPercentage and the actual winPercentage\n",
    "i=0\n",
    "for index, row in df_teams_2010.iterrows():\n",
    "    print(f\"Team: {row['tmID']}\\tPredicted winPercentage: {y_pred_best[i]}\\tActual winPercentage: {row['winPercentage']}\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b04a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eastern Conference\n",
      "IND with probality of 0.6224460680592554\n",
      "DET with probality of 0.5375042246060031\n",
      "ATL with probality of 0.5328349734825353\n",
      "WAS with probality of 0.5036095192621921\n",
      "Western Conference\n",
      "PHO with probality of 0.6554687810090237\n",
      "SEA with probality of 0.5679694854714996\n",
      "LAS with probality of 0.5442391512019968\n",
      "SAS with probality of 0.5080640158984536\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# NOTE: This is tested against year 2009. It is able to predict the exact teams that made it to the playoffs because the dataset contains the playoff statistics features for that year.\n",
    "#      However, the teacher won't probably give us the playoff statistics for the year 2010, so we will have to predict the teams that will make it to the playoffs based on other features.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Make a prediction for the 2010 season\n",
    "# say which teams will make it to the playoffs ... only four teams from each conference make it to the playoffs\n",
    "\n",
    "df_teams_2010['confID'] = confIds\n",
    "\n",
    "# add predWinPercentage to df_teams_2010\n",
    "df_teams_2010['predWinPercentage'] = y_pred_best\n",
    "\n",
    "ea_conf = df_teams_2010[df_teams_2010.confID == 'EA']\n",
    "we_conf = df_teams_2010[df_teams_2010.confID == 'WE']\n",
    "\n",
    "\n",
    "# get the top 4 teams from each conference\n",
    "ea_conf = ea_conf.sort_values(by=['predWinPercentage'], ascending=False)\n",
    "we_conf = we_conf.sort_values(by=['predWinPercentage'], ascending=False)\n",
    "\n",
    "\n",
    "# print the teams that will make it to the playoffs\n",
    "\n",
    "print(\"Eastern Conference\")\n",
    "for index, row in ea_conf.head(4).iterrows():\n",
    "    print(f\"{row['tmID']} with probality of {row['predWinPercentage']}\")\n",
    "print(\"Western Conference\")\n",
    "for index, row in we_conf.head(4).iterrows():\n",
    "    print(f\"{row['tmID']} with probality of {row['predWinPercentage']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6433bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def expanding_window_cross_validation(data, model_func, features, n_training_years):\n",
    "    accuracy_results = []\n",
    "    model = model_func()\n",
    "\n",
    "    for i in range(1, n_training_years):\n",
    "        train_data = data[data['year'].between(1, i)]\n",
    "        test_data = data[data['year'] == (i + 1)]\n",
    "\n",
    "        X_train, X_test = train_data[features], test_data[features]\n",
    "        y_train, y_test = train_data['playoff'], test_data['playoff']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy_results.append(accuracy)\n",
    "\n",
    "    return accuracy_results, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f897766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_decay_cross_validation(data, model_func, features, n_training_years, decay_rate=0.5):\n",
    "    accuracy_results = []\n",
    "    model = model_func()\n",
    "\n",
    "    for i in range(1, n_training_years):\n",
    "        train_data = data[data['year'].between(1, i)]\n",
    "        test_data = data[data['year'] == (i + 1)]\n",
    "\n",
    "        X_train, X_test = train_data[features], test_data[features]\n",
    "        y_train, y_test = train_data['playoff'], test_data['playoff']\n",
    "\n",
    "        # Apply weight to older data\n",
    "        weight = decay_rate ** (n_training_years - i - 1)\n",
    "        sample_weight = [weight] * len(X_train)\n",
    "\n",
    "        if type(model_func()).__name__ in [\"KNeighborsClassifier\", \"MLPClassifier\"]:\n",
    "            model.fit(X_train, y_train)  # This model don't support sample weights\n",
    "        else:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy_results.append(accuracy)\n",
    "\n",
    "    return accuracy_results, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c3c79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_cross_validation(data, model_func, features, n_training_years, window_size):\n",
    "    accuracy_results = []\n",
    "    model = model_func()\n",
    "\n",
    "    for i in range(1, n_training_years - window_size + 1):\n",
    "        train_data = data[data['year'].between(i, i + window_size - 1)]\n",
    "        test_data = data[data['year'] == (i + window_size)]\n",
    "\n",
    "        X_train, X_test = train_data[features], test_data[features]\n",
    "        y_train, y_test = train_data['playoff'], test_data['playoff']\n",
    "\n",
    "        # print(F\"Window train: {train_data['year'].unique()}\\nWindow test: {test_data['year'].unique()}\\n\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracy_results.append(accuracy)\n",
    "\n",
    "    return accuracy_results, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a6f31ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Define a list of lambda functions for different models with hyperparameters\n",
    "models = [\n",
    "    lambda: RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    #lambda: LogisticRegression(max_iter=1000, random_state=42),\n",
    "    lambda: SVC(C=1.0, kernel='rbf', probability=True),\n",
    "    lambda: GaussianNB(),\n",
    "    lambda: KNeighborsClassifier(n_neighbors=5),\n",
    "    lambda: DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    lambda: MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c997a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wnba_data = pd.read_csv(\"dataset/cleaned/teams.csv\")\n",
    "n_training_years = 9 # 9 years of data and 1 year to predict\n",
    "\n",
    "# Selecting the features and target\n",
    "features = ['attend','RoundReached','o_oreb', 'o_dreb', 'o_pf', 'o_stl', 'o_blk', 'o_pts', 'd_oreb', 'd_dreb', 'd_asts', 'd_pf', 'd_to', 'd_blk', 'd_pts', 'min', 'attend', 'RoundReached',\n",
    "            'winPercentage', 'homeWinPercentage', 'awayWinPercentage', 'of_goal', 'of_3pt', 'of_throw', 'of_reb', 'of_assist', 'df_goal', 'df_3pt', 'df_throw', 'df_reb', 'df_steal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ecea4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Model name: RandomForestClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: SVC\n",
      "Accuracy results for each iteration: [0.56, 0.75, 0.21, 0.69, 0.62, 0.64, 0.69, 0.64]\n",
      "Average accuracy: 0.6\n",
      "=====================================\n",
      "Model name: GaussianNB\n",
      "Accuracy results for each iteration: [0.81, 0.94, 0.43, 0.85, 0.85, 0.71, 0.85, 1.0]\n",
      "Average accuracy: 0.8\n",
      "=====================================\n",
      "Model name: KNeighborsClassifier\n",
      "Accuracy results for each iteration: [0.56, 0.62, 0.5, 0.92, 0.38, 0.43, 0.46, 0.57]\n",
      "Average accuracy: 0.56\n",
      "=====================================\n",
      "Model name: DecisionTreeClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: GradientBoostingClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: MLPClassifier\n",
      "Accuracy results for each iteration: [0.5, 0.5, 0.57, 0.62, 0.62, 0.57, 0.62, 0.57]\n",
      "Average accuracy: 0.57\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    accuracy_results, final_model = expanding_window_cross_validation(\n",
    "        wnba_data, model, features, n_training_years)\n",
    "\n",
    "    avg = round(sum(accuracy_results) / len(accuracy_results), 2)\n",
    "\n",
    "    print(f\"=====================================\")\n",
    "    print(\"Model name:\", type(model()).__name__)\n",
    "    print(\"Accuracy results for each iteration:\",\n",
    "          [round(x, 2) for x in accuracy_results])\n",
    "    print(\"Average accuracy:\", avg)\n",
    "\n",
    "print(\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30bc9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Model name: RandomForestClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: SVC\n",
      "Accuracy results for each iteration: [0.56, 0.75, 0.21, 0.62, 0.62, 0.57, 0.69, 0.64]\n",
      "Average accuracy: 0.58\n",
      "=====================================\n",
      "Model name: GaussianNB\n",
      "Accuracy results for each iteration: [0.81, 0.94, 0.43, 0.85, 0.85, 0.71, 0.85, 1.0]\n",
      "Average accuracy: 0.8\n",
      "=====================================\n",
      "Model name: KNeighborsClassifier\n",
      "Accuracy results for each iteration: [0.56, 0.62, 0.5, 0.92, 0.38, 0.43, 0.46, 0.57]\n",
      "Average accuracy: 0.56\n",
      "=====================================\n",
      "Model name: DecisionTreeClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: GradientBoostingClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "=====================================\n",
      "Model name: MLPClassifier\n",
      "Accuracy results for each iteration: [0.5, 0.5, 0.57, 0.62, 0.62, 0.57, 0.62, 0.57]\n",
      "Average accuracy: 0.57\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    accuracy_results, final_model = expanding_window_decay_cross_validation(\n",
    "        wnba_data, model, features, n_training_years)\n",
    "\n",
    "    avg = round(sum(accuracy_results) / len(accuracy_results), 2)\n",
    "\n",
    "    print(f\"=====================================\")\n",
    "    print(\"Model name:\", type(model()).__name__)\n",
    "    print(\"Accuracy results for each iteration:\",\n",
    "          [round(x, 2) for x in accuracy_results])\n",
    "    print(\"Average accuracy:\", avg)\n",
    "\n",
    "print(\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc22f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: RandomForestClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: SVC\n",
      "Accuracy results for each iteration: [0.21, 0.62, 0.62, 0.57, 0.69, 0.64]\n",
      "Average accuracy: 0.56\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: GaussianNB\n",
      "Accuracy results for each iteration: [0.43, 0.69, 0.69, 0.71, 0.69, 1.0]\n",
      "Average accuracy: 0.7\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: KNeighborsClassifier\n",
      "Accuracy results for each iteration: [0.5, 0.77, 0.46, 0.57, 0.54, 0.71]\n",
      "Average accuracy: 0.59\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: DecisionTreeClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: GradientBoostingClassifier\n",
      "Accuracy results for each iteration: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy: 1.0\n",
      "Window train: [1 2 3]\n",
      "Window test: [4]\n",
      "\n",
      "Window train: [2 3 4]\n",
      "Window test: [5]\n",
      "\n",
      "Window train: [3 4 5]\n",
      "Window test: [6]\n",
      "\n",
      "Window train: [4 5 6]\n",
      "Window test: [7]\n",
      "\n",
      "Window train: [5 6 7]\n",
      "Window test: [8]\n",
      "\n",
      "Window train: [6 7 8]\n",
      "Window test: [9]\n",
      "\n",
      "=====================================\n",
      "Model name: MLPClassifier\n",
      "Accuracy results for each iteration: [0.57, 0.62, 0.62, 0.57, 0.38, 0.57]\n",
      "Average accuracy: 0.55\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    accuracy_results, final_model = sliding_window_cross_validation(\n",
    "        wnba_data, model, features, n_training_years, 3)\n",
    "\n",
    "    avg = round(sum(accuracy_results) / len(accuracy_results), 2)\n",
    "\n",
    "    print(f\"=====================================\")\n",
    "    print(\"Model name:\", type(model()).__name__)\n",
    "    print(\"Accuracy results for each iteration:\",\n",
    "          [round(x, 2) for x in accuracy_results])\n",
    "    print(\"Average accuracy:\", avg)\n",
    "\n",
    "print(\"=====================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
