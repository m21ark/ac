{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autosklearn.classification\n",
    "from pipeline import *\n",
    "\n",
    "df_coaches = pd.read_csv('dataset/cleaned/coaches.csv')\n",
    "# models = [\n",
    "#     lambda: RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     #lambda: LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     lambda: SVC(C=1.0, kernel='rbf', probability=True),\n",
    "#     lambda: GaussianNB(),\n",
    "#     lambda: KNeighborsClassifier(n_neighbors=5),\n",
    "#     lambda: DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "#     lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "#     lambda: MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "# ]\n",
    "\n",
    "# After grid hyperparameter tuning\n",
    "models = [\n",
    "    lambda: RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    lambda: SVC(C=0.1, kernel='linear', probability=True),\n",
    "    lambda: GaussianNB(),\n",
    "    lambda: KNeighborsClassifier(n_neighbors=15, weights='uniform'),\n",
    "    lambda: DecisionTreeClassifier(max_depth=5, min_samples_split=2, random_state=42),\n",
    "    lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=42),\n",
    "    lambda: MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "]\n",
    "\n",
    "def run_window_decay(model, year):\n",
    "    l = []\n",
    "\n",
    "\n",
    "    clf = model()\n",
    "    decay_rate=0.1\n",
    "    df_teams_merged = []\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(2, year + 1):\n",
    "        df_teams_merged = pipeline_clf(year=i)\n",
    "        weight = decay_rate ** (10 - i - 1)\n",
    "\n",
    "        df_teams_merged['confID'] = df_teams_merged['confID'].replace({'EA': 0, 'WE': 1})\n",
    "\n",
    "        train = df_teams_merged[df_teams_merged['year'] < i]\n",
    "        test = df_teams_merged[df_teams_merged['year'] == i]\n",
    "\n",
    "        #if (year == i):\n",
    "        #    break\n",
    "\n",
    "\n",
    "        X_train = train[train.drop(['playoff', 'year', 'tmID'], axis=1).columns]\n",
    "        y_train = train['playoff']\n",
    "        sample_weight = [weight] * len(X_train)\n",
    "\n",
    "        if type(model()).__name__ in [\"KNeighborsClassifier\", \"MLPClassifier\"]:\n",
    "            clf.fit(X_train, y_train)  # This model don't support sample weights\n",
    "        else:\n",
    "            clf.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    predictions = clf.predict_proba(test.drop(['playoff', 'year', 'tmID'], axis=1))[:, 1]\n",
    "    test['predictions'] = predictions\n",
    "    df_teams_merged['predictions'] = 0\n",
    "    df_teams_merged.loc[df_teams_merged['year'] == year, 'predictions'] = predictions\n",
    "\n",
    "    df_teams_merged['confID'] = df_teams_merged['confID'].replace({0: 'EA', 1 : 'WE'})\n",
    "\n",
    "    # print the year and the predicted scores\n",
    "    # print(df_teams_merged[df_teams_merged['year'] == year][['tmID', 'confID', 'predictions', 'awards', 'offensive_strength']].sort_values(by='predictions', ascending=False))\n",
    "\n",
    "\n",
    "    df_teams, ea_teams, we_teams = classify_playoff_entry(\n",
    "            df_teams_merged, year)\n",
    "\n",
    "    ea_predictions = ea_teams['tmID'].unique()\n",
    "    we_predictions = we_teams['tmID'].unique()\n",
    "\n",
    "\n",
    "    accuracy = calculate_playoff_accuracy(\n",
    "        year, ea_predictions, we_predictions, display_results = False)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_year(11,display_results=True, model=models[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_year(11,display_results=True, model=models[1])['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_year(11,display_results=True, model=models[0])['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import *\n",
    "\n",
    "def check_accuracy_by_year2(models):\n",
    "    # Create a list to store accuracy values for each model\n",
    "    accs = []\n",
    "    model_accs = []\n",
    "    roc_curves = []\n",
    "    model_roc_curve = []\n",
    "    \n",
    "    # Define the years\n",
    "    years = list(range(10, 11))\n",
    "    \n",
    "    # Calculate accuracy for each year for each model\n",
    "    models_grid = [\n",
    "        lambda: RandomForestClassifier(),\n",
    "        # LogisticRegression(),\n",
    "        lambda: SVC(probability=True),\n",
    "        lambda: GaussianNB(),\n",
    "        lambda: KNeighborsClassifier(),\n",
    "        lambda: DecisionTreeClassifier(),\n",
    "        lambda: GradientBoostingClassifier(),\n",
    "        lambda: MLPClassifier()\n",
    "    ]\n",
    "\n",
    "    param_grids = [\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'random_state': [42]\n",
    "        },\n",
    "        {\n",
    "            'C': [1.0, 0.1, 0.01],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'probability': [True]\n",
    "        },\n",
    "        {   # GaussianNB\n",
    "            'var_smoothing': [1e-09, 1e-08, 1e-07]\n",
    "        },\n",
    "        {\n",
    "            'n_neighbors': [5, 10, 15],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        {\n",
    "            'max_depth': [5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'random_state': [42]\n",
    "        },\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'random_state': [42]\n",
    "        },\n",
    "        {\n",
    "            'hidden_layer_sizes': [(100, 50), (200, 100), (300, 150)],\n",
    "            'max_iter': [1000, 2000, 3000],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        # model_accs = [run_window_decay(model, year) for year in years]\n",
    "        # model_accs = [pipeline_year(year, model=model, display_results=False)['precision'] for year in years]\n",
    "        # model_accs = [pipeline_year_grid_search(year, model=model, parameters=param_grids[i], display_results=False)['precision'] for year in years]\n",
    "        model_roc_curve = [pipeline_year(year, model=model, display_results=False)['roc'] for year in years]\n",
    "\n",
    "        # accs.append(model_accs)\n",
    "        roc_curves.append(model_roc_curve)\n",
    "    #accs = [[75.0, 50.0, 75.0, 75.0, 87.5, 87.5, 62.5, 87.5, 87.5], [50.0, 50.0, 87.5, 50.0, 62.5, 25.0, 62.5, 62.5, 75.0], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 75.0, 87.5], [50.0, 50.0, 62.5, 62.5, 62.5, 87.5, 62.5, 62.5, 75.0], [62.5, 50.0, 87.5, 62.5, 75.0, 75.0, 62.5, 50.0, 75.0], [50.0, 50.0, 50.0, 87.5, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 50.0, 75.0, 75.0, 100.0, 62.5, 87.5, 75.0]]\n",
    "\n",
    "\n",
    "    # Plot the accuracy line graphs for each model\n",
    "    # for i, model_acc in enumerate(accs):\n",
    "    #     plt.plot(years, model_acc, label=f\"{type(models[i]()).__name__ }\", marker='o', linestyle='-', alpha=0.5)\n",
    "\n",
    "    # # Add legend\n",
    "    # plt.legend()\n",
    "\n",
    "    # # Set Y-axis limits\n",
    "    # plt.ylim(0, 100)\n",
    "\n",
    "    # plt.xlabel(\"Year\")\n",
    "    # plt.ylabel(\"Precision\")\n",
    "    # plt.title(\"Precision by year\")\n",
    "    # plt.grid(True)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # Plot the ROC line graphs for each model\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for i, model_roc in enumerate(roc_curves):\n",
    "        for j in range(len(years)):\n",
    "            fpr = model_roc[j][0]\n",
    "            tpr = model_roc[j][1]\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'AUC = {auc(fpr, tpr):.2f} - {type(models[i]()).__name__ }', marker='o', linestyle='-')\n",
    "\n",
    "\n",
    "    # Add legend\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for year 10')  \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Add labels for each data point\n",
    "    # for i, model_acc in enumerate(accs):\n",
    "    #     for j, acc in enumerate(model_acc):\n",
    "    #         plt.text(years[j], acc, f\"{acc:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    \n",
    "\n",
    "check_accuracy_by_year2(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_window_decay(models[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accs = [[75.0, 50.0, 75.0, 75.0, 87.5, 87.5, 62.5, 87.5, 87.5], [50.0, 50.0, 87.5, 50.0, 62.5, 25.0, 62.5, 62.5, 75.0], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 75.0, 87.5], [50.0, 50.0, 62.5, 62.5, 62.5, 87.5, 62.5, 62.5, 75.0], [62.5, 50.0, 87.5, 62.5, 75.0, 75.0, 62.5, 50.0, 75.0], [50.0, 50.0, 50.0, 87.5, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 50.0, 75.0, 75.0, 100.0, 62.5, 87.5, 75.0]]\n",
    "accs_grid = [[62.5, 50.0, 75.0, 75.0, 75.0, 100.0, 62.5, 87.5, 87.5], [75.0, 50.0, 62.5, 75.0, 87.5, 100.0, 62.5, 75.0, 87.5], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 75.0, 62.5, 87.5, 100.0, 62.5, 75.0, 75.0], [62.5, 62.5, 62.5, 62.5, 75.0, 50.0, 62.5, 50.0, 87.5], [50.0, 50.0, 62.5, 75.0, 75.0, 100.0, 62.5, 87.5, 87.5], [50.0, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 62.5, 75.0]]\n",
    "\n",
    "years = list(range(2, 11))\n",
    "model_names = [type(model()).__name__ for model in models]\n",
    "\n",
    "# Calculate the average accuracy and standard deviation for each model\n",
    "avg_accuracies = [np.mean(model_accs) for model_accs in accs]\n",
    "std_accuracies = [np.std(model_accs) for model_accs in accs]\n",
    "\n",
    "print(avg_accuracies)\n",
    "print(std_accuracies)\n",
    "\n",
    "# Find the index of the model with the highest average accuracy and lowest standard deviation\n",
    "best_avg_model_index = np.argmax(avg_accuracies)\n",
    "most_stable_model_index = np.argmin(std_accuracies)\n",
    "\n",
    "# Plot the accuracy line graphs for the best average model and the most stable model\n",
    "plt.plot(years, accs[best_avg_model_index], label=f\"Best Average Precision: {model_names[best_avg_model_index]}\", marker='o', linestyle='-', alpha=0.5)\n",
    "plt.plot(years, accs[most_stable_model_index], label=f\"Most Stable: {model_names[most_stable_model_index]}\", marker='o', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Set Y-axis limits\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision by year\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accs = [[75.0, 50.0, 75.0, 75.0, 87.5, 87.5, 62.5, 87.5, 87.5], [50.0, 50.0, 87.5, 50.0, 62.5, 25.0, 62.5, 62.5, 75.0], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 75.0, 87.5], [50.0, 50.0, 62.5, 62.5, 62.5, 87.5, 62.5, 62.5, 75.0], [62.5, 50.0, 87.5, 62.5, 75.0, 75.0, 62.5, 50.0, 75.0], [50.0, 50.0, 50.0, 87.5, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 50.0, 75.0, 75.0, 100.0, 62.5, 87.5, 75.0]]\n",
    "accs_grid = [[62.5, 50.0, 75.0, 75.0, 75.0, 100.0, 62.5, 87.5, 87.5], [75.0, 50.0, 62.5, 75.0, 87.5, 100.0, 62.5, 75.0, 87.5], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 75.0, 62.5, 87.5, 100.0, 62.5, 75.0, 75.0], [62.5, 62.5, 62.5, 62.5, 75.0, 50.0, 62.5, 50.0, 87.5], [50.0, 50.0, 62.5, 75.0, 75.0, 100.0, 62.5, 87.5, 87.5], [50.0, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 62.5, 75.0]]\n",
    "\n",
    "years = list(range(2, 11))\n",
    "model_names = [type(model()).__name__ for model in models]\n",
    "\n",
    "# Calculate the average accuracy and standard deviation for each model\n",
    "avg_accuracies = [np.mean(model_accs) for model_accs in accs]\n",
    "std_accuracies = [np.std(model_accs) for model_accs in accs]\n",
    "\n",
    "print(list(zip(model_names, avg_accuracies)))\n",
    "print(std_accuracies)\n",
    "\n",
    "# Plot KNN before and after grid search\n",
    "plt.plot(years, accs[6], label=f\"Random Forest before\", marker='o', linestyle='-', alpha=0.5)\n",
    "plt.plot(years, accs_grid[6], label=f\"Random Forest after\", marker='o', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Set Y-axis limits\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision by year\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
