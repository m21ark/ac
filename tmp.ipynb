{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autosklearn.classification\n",
    "from pipeline import *\n",
    "\n",
    "# pipeline_year(10)\n",
    "\n",
    "df_coaches = pd.read_csv('dataset/cleaned/coaches.csv')\n",
    "models = [\n",
    "    lambda: RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    #lambda: LogisticRegression(max_iter=1000, random_state=42),\n",
    "    lambda: SVC(C=1.0, kernel='rbf', probability=True),\n",
    "    lambda: GaussianNB(),\n",
    "    lambda: KNeighborsClassifier(n_neighbors=5),\n",
    "    lambda: DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    lambda: GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    lambda: MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "]\n",
    "\n",
    "def run_window_decay(model, year):\n",
    "    l = []\n",
    "\n",
    "    # param_grids = [\n",
    "    #     {\n",
    "    #         'n_estimators': [100, 200, 300],\n",
    "    #         'max_depth': [5, 10, None],\n",
    "    #         'min_samples_split': [2, 5, 10],\n",
    "    #         'random_state': [42]\n",
    "    #     },\n",
    "    #     {\n",
    "    #         'C': [1.0, 0.1, 0.01],\n",
    "    #         'kernel': ['rbf', 'linear'],\n",
    "    #         'probability': [True]\n",
    "    #     },\n",
    "    #     {},\n",
    "    #     {\n",
    "    #         'n_neighbors': [5, 10, 15],\n",
    "    #         'weights': ['uniform', 'distance']\n",
    "    #     },\n",
    "    #     {\n",
    "    #         'max_depth': [5, 10, 15],\n",
    "    #         'min_samples_split': [2, 5, 10],\n",
    "    #         'random_state': [42]\n",
    "    #     },\n",
    "    #     {\n",
    "    #         'n_estimators': [100, 200, 300],\n",
    "    #         'learning_rate': [0.1, 0.01, 0.001],\n",
    "    #         'max_depth': [3, 5, 7],\n",
    "    #         'random_state': [42]\n",
    "    #     },\n",
    "    #     {\n",
    "    #         'hidden_layer_sizes': [(100, 50), (200, 100), (300, 150)],\n",
    "    #         'max_iter': [1000, 2000, 3000],\n",
    "    #         'random_state': [42]\n",
    "    #     }\n",
    "    #     ]\n",
    "\n",
    "    clf = model()\n",
    "    decay_rate=0.1\n",
    "    df_teams_merged = []\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(2, year + 1):\n",
    "        df_teams_merged = pipeline_clf(year=i)\n",
    "        weight = decay_rate ** (10 - i - 1)\n",
    "\n",
    "        df_teams_merged['confID'] = df_teams_merged['confID'].replace({'EA': 0, 'WE': 1})\n",
    "\n",
    "        train = df_teams_merged[df_teams_merged['year'] < i]\n",
    "        test = df_teams_merged[df_teams_merged['year'] == i]\n",
    "\n",
    "        #if (year == i):\n",
    "        #    break\n",
    "\n",
    "\n",
    "        X_train = train[train.drop(['playoff', 'year', 'tmID'], axis=1).columns]\n",
    "        y_train = train['playoff']\n",
    "        sample_weight = [weight] * len(X_train)\n",
    "\n",
    "        # grid_search_results = []\n",
    "        # best_model = None\n",
    "        # best_score = 0\n",
    "\n",
    "        # # Perform grid search for each model\n",
    "        # for model, param_grid in zip(models, param_grids):\n",
    "        #     grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        #     grid_search.fit(train.drop(['playoff', 'year', 'tmID'], axis=1), train['playoff'])  # Replace X and y with your data\n",
    "        #     grid_search_results.append(grid_search)\n",
    "        #     if grid_search.best_score_ > best_score:\n",
    "        #         best_score = grid_search.best_score_\n",
    "        #         best_model = grid_search.best_estimator_\n",
    "\n",
    "        # for model, grid_search_result in zip(models, grid_search_results):\n",
    "        #     print(f\"Best parameters for {model.__class__.__name__}: {grid_search_result.best_params_}\")\n",
    "        #     print(f\"Best score for {model.__class__.__name__}: {grid_search_result.best_score_}\")\n",
    "\n",
    "        # clf = best_model\n",
    "\n",
    "        if type(model()).__name__ in [\"KNeighborsClassifier\", \"MLPClassifier\"]:\n",
    "            clf.fit(X_train, y_train)  # This model don't support sample weights\n",
    "        else:\n",
    "            clf.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    predictions = clf.predict_proba(test.drop(['playoff', 'year', 'tmID'], axis=1))[:, 1]\n",
    "    test['predictions'] = predictions\n",
    "    df_teams_merged['predictions'] = 0\n",
    "    df_teams_merged.loc[df_teams_merged['year'] == year, 'predictions'] = predictions\n",
    "\n",
    "    df_teams_merged['confID'] = df_teams_merged['confID'].replace({0: 'EA', 1 : 'WE'})\n",
    "\n",
    "    # print the year and the predicted scores\n",
    "    # print(df_teams_merged[df_teams_merged['year'] == year][['tmID', 'confID', 'predictions', 'awards', 'offensive_strength']].sort_values(by='predictions', ascending=False))\n",
    "\n",
    "\n",
    "    df_teams, ea_teams, we_teams = classify_playoff_entry(\n",
    "            df_teams_merged, year)\n",
    "\n",
    "    ea_predictions = ea_teams['tmID'].unique()\n",
    "    we_predictions = we_teams['tmID'].unique()\n",
    "\n",
    "\n",
    "    accuracy = calculate_playoff_accuracy(\n",
    "        year, ea_predictions, we_predictions, display_results = False)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_year(8,display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import *\n",
    "\n",
    "def check_accuracy_by_year2(models):\n",
    "    # Create a list to store accuracy values for each model\n",
    "    accs = []\n",
    "    \n",
    "    # Define the years\n",
    "    years = list(range(2, 11))\n",
    "    \n",
    "    # Calculate accuracy for each year for each model\n",
    "    for model in models:\n",
    "        model_accs = [run_window_decay(model, year) for year in years]\n",
    "        accs.append(model_accs)\n",
    "    #accs = [[75.0, 50.0, 75.0, 75.0, 87.5, 87.5, 62.5, 87.5, 87.5], [50.0, 50.0, 87.5, 50.0, 62.5, 25.0, 62.5, 62.5, 75.0], [62.5, 50.0, 62.5, 75.0, 75.0, 87.5, 62.5, 75.0, 87.5], [50.0, 50.0, 62.5, 62.5, 62.5, 87.5, 62.5, 62.5, 75.0], [62.5, 50.0, 87.5, 62.5, 75.0, 75.0, 62.5, 50.0, 75.0], [50.0, 50.0, 50.0, 87.5, 75.0, 87.5, 62.5, 62.5, 87.5], [62.5, 50.0, 50.0, 75.0, 75.0, 100.0, 62.5, 87.5, 75.0]]\n",
    "    print(accs)\n",
    "\n",
    "    # Plot the accuracy line graphs for each model\n",
    "    for i, model_acc in enumerate(accs):\n",
    "        plt.plot(years, model_acc, label=f\"{type(models[i]()).__name__ }\", marker='o', linestyle='-', alpha=0.5)\n",
    "\n",
    "    # Add labels for each data point\n",
    "    # for i, model_acc in enumerate(accs):\n",
    "    #     for j, acc in enumerate(model_acc):\n",
    "    #         plt.text(years[j], acc, f\"{acc:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Set Y-axis limits\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy by year\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "check_accuracy_by_year2(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_window_decay(models[0], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
